{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bài tập 1\n",
    "- Tạo mảng 1 chiều $x$ gồm n số thực\n",
    "- Chọn 3 hàm số tuỳ ý $f_1(x)$, $f_2(x)$, $f_3(x)$. Tạo 3 mảng bằng cách truyền $x$ vào trong 3 hàm số.\n",
    "- Ghép bốn mảng một chiều thành một mảng hai chiều kích thước $n\\times4$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 10\n",
    "arr1 = np.arange(n)\n",
    "arr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Khởi tạo 3 hàm số\n",
    "\n",
    "def f1_x(arr):\n",
    "    return arr * 2\n",
    "\n",
    "def f2_x(arr):\n",
    "    return arr ** 2\n",
    "\n",
    "def f3_x(arr):\n",
    "    return arr / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hàm số f1(x) = [ 0  2  4  6  8 10 12 14 16 18]\n",
      "Hàm số f1(x) = [ 0  1  4  9 16 25 36 49 64 81]\n",
      "Hàm số f1(x) = [0.  0.5 1.  1.5 2.  2.5 3.  3.5 4.  4.5]\n"
     ]
    }
   ],
   "source": [
    "arr2 = f1_x(arr1)\n",
    "arr3 = f2_x(arr1)\n",
    "arr4 = f3_x(arr1)\n",
    "\n",
    "print(f\"Hàm số f1(x) = {arr2}\")\n",
    "print(f\"Hàm số f1(x) = {arr3}\")\n",
    "print(f\"Hàm số f1(x) = {arr4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0. ,  0. ,  0. ,  0. ],\n",
       "       [ 1. ,  2. ,  1. ,  0.5],\n",
       "       [ 2. ,  4. ,  4. ,  1. ],\n",
       "       [ 3. ,  6. ,  9. ,  1.5],\n",
       "       [ 4. ,  8. , 16. ,  2. ],\n",
       "       [ 5. , 10. , 25. ,  2.5],\n",
       "       [ 6. , 12. , 36. ,  3. ],\n",
       "       [ 7. , 14. , 49. ,  3.5],\n",
       "       [ 8. , 16. , 64. ,  4. ],\n",
       "       [ 9. , 18. , 81. ,  4.5]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ghép 4 mảng một chiều thành một mảng 2 chiều kích thước nx4\n",
    "\n",
    "arr2d = np.vstack([arr1, arr2, arr3, arr4])\n",
    "arr2d.T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bài tập 2\n",
    "- Tải dữ liệu file `heart_rate.txt` vào trong mảng `a`\n",
    "- Thực hiện mô tả thống kê với các biến `Time` và `Heart Rate`: Cỡ mẫu, trung bình, trung vị, độ lệch chuẩn, giá trị lớn nhất, nhỏ nhất, phần tư Q1, Q2 và Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0.,  103.],\n",
       "       [   5.,  103.],\n",
       "       [  10.,  103.],\n",
       "       [  15.,  105.],\n",
       "       [  20.,  108.],\n",
       "       [  25.,  110.],\n",
       "       [  30.,  110.],\n",
       "       [  35.,  112.],\n",
       "       [  40.,  112.],\n",
       "       [  45.,  114.],\n",
       "       [  50.,  114.],\n",
       "       [  55.,  117.],\n",
       "       [  60.,  117.],\n",
       "       [  65.,  118.],\n",
       "       [  70.,  119.],\n",
       "       [  75.,  119.],\n",
       "       [  80.,  120.],\n",
       "       [  85.,  121.],\n",
       "       [  90.,  121.],\n",
       "       [  95.,  122.],\n",
       "       [ 100.,  123.],\n",
       "       [ 105.,  124.],\n",
       "       [ 110.,  124.],\n",
       "       [ 115.,  125.],\n",
       "       [ 120.,  126.],\n",
       "       [ 125.,  127.],\n",
       "       [ 130.,  128.],\n",
       "       [ 135.,  127.],\n",
       "       [ 140.,  128.],\n",
       "       [ 145.,  128.],\n",
       "       [ 150.,  129.],\n",
       "       [ 155.,  129.],\n",
       "       [ 160.,  130.],\n",
       "       [ 165.,  131.],\n",
       "       [ 170.,  132.],\n",
       "       [ 175.,  132.],\n",
       "       [ 180.,  132.],\n",
       "       [ 185.,  133.],\n",
       "       [ 190.,  134.],\n",
       "       [ 195.,  135.],\n",
       "       [ 200.,  135.],\n",
       "       [ 205.,  135.],\n",
       "       [ 210.,  135.],\n",
       "       [ 215.,  136.],\n",
       "       [ 220.,  136.],\n",
       "       [ 225.,  136.],\n",
       "       [ 230.,  137.],\n",
       "       [ 235.,  137.],\n",
       "       [ 240.,  137.],\n",
       "       [ 245.,  137.],\n",
       "       [ 250.,  138.],\n",
       "       [ 255.,  138.],\n",
       "       [ 260.,  138.],\n",
       "       [ 265.,  138.],\n",
       "       [ 270.,  139.],\n",
       "       [ 275.,  138.],\n",
       "       [ 280.,  138.],\n",
       "       [ 285.,  138.],\n",
       "       [ 290.,  138.],\n",
       "       [ 295.,  138.],\n",
       "       [ 300.,  138.],\n",
       "       [ 305.,  138.],\n",
       "       [ 310.,  138.],\n",
       "       [ 315.,  139.],\n",
       "       [ 320.,  140.],\n",
       "       [ 325.,  141.],\n",
       "       [ 330.,  141.],\n",
       "       [ 335.,  141.],\n",
       "       [ 340.,  141.],\n",
       "       [ 345.,  142.],\n",
       "       [ 350.,  141.],\n",
       "       [ 355.,  142.],\n",
       "       [ 360.,  142.],\n",
       "       [ 365.,  143.],\n",
       "       [ 370.,  143.],\n",
       "       [ 375.,  143.],\n",
       "       [ 380.,  143.],\n",
       "       [ 385.,  144.],\n",
       "       [ 390.,  144.],\n",
       "       [ 395.,  144.],\n",
       "       [ 400.,  145.],\n",
       "       [ 405.,  144.],\n",
       "       [ 410.,  145.],\n",
       "       [ 415.,  144.],\n",
       "       [ 420.,  145.],\n",
       "       [ 425.,  145.],\n",
       "       [ 430.,  144.],\n",
       "       [ 435.,  144.],\n",
       "       [ 440.,  144.],\n",
       "       [ 445.,  144.],\n",
       "       [ 450.,  145.],\n",
       "       [ 455.,  144.],\n",
       "       [ 460.,  144.],\n",
       "       [ 465.,  144.],\n",
       "       [ 470.,  145.],\n",
       "       [ 475.,  145.],\n",
       "       [ 480.,  146.],\n",
       "       [ 485.,  147.],\n",
       "       [ 490.,  147.],\n",
       "       [ 495.,  147.],\n",
       "       [ 500.,  147.],\n",
       "       [ 505.,  147.],\n",
       "       [ 510.,  147.],\n",
       "       [ 515.,  147.],\n",
       "       [ 520.,  147.],\n",
       "       [ 525.,  147.],\n",
       "       [ 530.,  147.],\n",
       "       [ 535.,  147.],\n",
       "       [ 540.,  147.],\n",
       "       [ 545.,  147.],\n",
       "       [ 550.,  147.],\n",
       "       [ 555.,  147.],\n",
       "       [ 560.,  146.],\n",
       "       [ 565.,  147.],\n",
       "       [ 570.,  146.],\n",
       "       [ 575.,  146.],\n",
       "       [ 580.,  146.],\n",
       "       [ 585.,  146.],\n",
       "       [ 590.,  147.],\n",
       "       [ 595.,  147.],\n",
       "       [ 600.,  147.],\n",
       "       [ 605.,  148.],\n",
       "       [ 610.,  148.],\n",
       "       [ 615.,  148.],\n",
       "       [ 620.,  147.],\n",
       "       [ 625.,  147.],\n",
       "       [ 630.,  148.],\n",
       "       [ 635.,  148.],\n",
       "       [ 640.,  148.],\n",
       "       [ 645.,  148.],\n",
       "       [ 650.,  148.],\n",
       "       [ 655.,  148.],\n",
       "       [ 660.,  147.],\n",
       "       [ 665.,  148.],\n",
       "       [ 670.,  147.],\n",
       "       [ 675.,  148.],\n",
       "       [ 680.,  148.],\n",
       "       [ 685.,  149.],\n",
       "       [ 690.,  148.],\n",
       "       [ 695.,  148.],\n",
       "       [ 700.,  149.],\n",
       "       [ 705.,  149.],\n",
       "       [ 710.,  149.],\n",
       "       [ 715.,  149.],\n",
       "       [ 720.,  149.],\n",
       "       [ 725.,  149.],\n",
       "       [ 730.,  149.],\n",
       "       [ 735.,  150.],\n",
       "       [ 740.,  150.],\n",
       "       [ 745.,  150.],\n",
       "       [ 750.,  150.],\n",
       "       [ 755.,  150.],\n",
       "       [ 760.,  150.],\n",
       "       [ 765.,  150.],\n",
       "       [ 770.,  149.],\n",
       "       [ 775.,  149.],\n",
       "       [ 780.,  149.],\n",
       "       [ 785.,  149.],\n",
       "       [ 790.,  149.],\n",
       "       [ 795.,  149.],\n",
       "       [ 800.,  148.],\n",
       "       [ 805.,  149.],\n",
       "       [ 810.,  149.],\n",
       "       [ 815.,  149.],\n",
       "       [ 820.,  149.],\n",
       "       [ 825.,  149.],\n",
       "       [ 830.,  149.],\n",
       "       [ 835.,  149.],\n",
       "       [ 840.,  148.],\n",
       "       [ 845.,  148.],\n",
       "       [ 850.,  148.],\n",
       "       [ 855.,  149.],\n",
       "       [ 860.,  150.],\n",
       "       [ 865.,  151.],\n",
       "       [ 870.,  151.],\n",
       "       [ 875.,  151.],\n",
       "       [ 880.,  151.],\n",
       "       [ 885.,  150.],\n",
       "       [ 890.,  151.],\n",
       "       [ 895.,  151.],\n",
       "       [ 900.,  149.],\n",
       "       [ 905.,  147.],\n",
       "       [ 910.,  146.],\n",
       "       [ 915.,  147.],\n",
       "       [ 920.,  150.],\n",
       "       [ 925.,  152.],\n",
       "       [ 930.,  153.],\n",
       "       [ 935.,  153.],\n",
       "       [ 940.,  153.],\n",
       "       [ 945.,  152.],\n",
       "       [ 950.,  152.],\n",
       "       [ 955.,  151.],\n",
       "       [ 960.,  151.],\n",
       "       [ 965.,  152.],\n",
       "       [ 970.,  152.],\n",
       "       [ 975.,  151.],\n",
       "       [ 980.,  152.],\n",
       "       [ 985.,  152.],\n",
       "       [ 990.,  152.],\n",
       "       [ 995.,  153.],\n",
       "       [1000.,  153.],\n",
       "       [1005.,  153.],\n",
       "       [1010.,  153.],\n",
       "       [1015.,  152.],\n",
       "       [1020.,  152.],\n",
       "       [1025.,  152.],\n",
       "       [1030.,  152.],\n",
       "       [1035.,  152.],\n",
       "       [1040.,  152.],\n",
       "       [1045.,  153.],\n",
       "       [1050.,  152.],\n",
       "       [1055.,  152.],\n",
       "       [1060.,  153.],\n",
       "       [1065.,  153.],\n",
       "       [1070.,  153.],\n",
       "       [1075.,  153.],\n",
       "       [1080.,  152.],\n",
       "       [1085.,  152.],\n",
       "       [1090.,  151.],\n",
       "       [1095.,  152.],\n",
       "       [1100.,  152.],\n",
       "       [1105.,  152.],\n",
       "       [1110.,  153.],\n",
       "       [1115.,  153.],\n",
       "       [1120.,  153.],\n",
       "       [1125.,  153.],\n",
       "       [1130.,  153.],\n",
       "       [1135.,  153.],\n",
       "       [1140.,  153.],\n",
       "       [1145.,  153.],\n",
       "       [1150.,  153.],\n",
       "       [1155.,  152.],\n",
       "       [1160.,  152.],\n",
       "       [1165.,  152.],\n",
       "       [1170.,  152.],\n",
       "       [1175.,  153.],\n",
       "       [1180.,  153.],\n",
       "       [1185.,  154.],\n",
       "       [1190.,  154.],\n",
       "       [1195.,  154.],\n",
       "       [1200.,  154.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = '/home/gudchant/data1-numpy/data1-numpy/excercises/heart_rate.txt'\n",
    "a = np.loadtxt(data, delimiter=',', skiprows=1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_time = a[:, 0]\n",
    "a_heart_rate = a[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cỡ mẫu Time: 241\n",
      "Cỡ mẫu Heart Rate: 241\n"
     ]
    }
   ],
   "source": [
    "print(f\"Cỡ mẫu Time: {np.size(a_time)}\")\n",
    "print(f\"Cỡ mẫu Heart Rate: {np.size(a_heart_rate)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trung bình Time: 600.0\n",
      "Trung bình Heart Rate: 142.98340248962654\n"
     ]
    }
   ],
   "source": [
    "print(f\"Trung bình Time: {np.mean(a_time)}\")\n",
    "print(f\"Trung bình Heart Rate: {np.mean(a_heart_rate)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trung vị Time: 600.0\n",
      "Trung vị Heart Rate: 147.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Trung vị Time: {np.median(a_time)}\")\n",
    "print(f\"Trung vị Heart Rate: {np.median(a_heart_rate)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Độ lệch chuẩn Time: 347.85054261852173\n",
      "Độ lệch chuẩn Heart Rate: 11.36346581057221\n"
     ]
    }
   ],
   "source": [
    "print(f\"Độ lệch chuẩn Time: {np.std(a_time)}\")\n",
    "print(f\"Độ lệch chuẩn Heart Rate: {np.std(a_heart_rate)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Giá trị lớn nhất Time: 1200.0\n",
      "Giá trị lớn nhât Heart Rate: 154.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Giá trị lớn nhất Time: {np.max(a_time)}\")\n",
    "print(f\"Giá trị lớn nhât Heart Rate: {np.max(a_heart_rate)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Giá trị nhỏ nhât Time: 0.0\n",
      "Giá trị nhỏ nhât Heart Rate: 103.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Giá trị nhỏ nhât Time: {np.min(a_time)}\")\n",
    "print(f\"Giá trị nhỏ nhât Heart Rate: {np.min(a_heart_rate)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Góc phần tư Q1 Time: 300.0\n",
      "Góc phần tư Q1 Heart Rate: 138.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Góc phần tư Q1 Time: {np.percentile(a_time, 25)}\")\n",
    "print(f\"Góc phần tư Q1 Heart Rate: {np.percentile(a_heart_rate, 25)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Góc phần tư Q2 Time: 600.0\n",
      "Góc phần tư Q2 Heart Rate: 147.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Góc phần tư Q2 Time: {np.percentile(a_time, 50)}\")\n",
    "print(f\"Góc phần tư Q2 Heart Rate: {np.percentile(a_heart_rate, 50)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Góc phần tư Q3 Time: 900.0\n",
      "Góc phần tư Q3 Heart Rate: 151.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Góc phần tư Q3 Time: {np.percentile(a_time, 75)}\")\n",
    "print(f\"Góc phần tư Q3 Heart Rate: {np.percentile(a_heart_rate, 75)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bài tập 3\n",
    "- Tạo một mảng 2-chiều `a` cỡ $m\\times n$\n",
    "- Các phần tử hàng đầu tiên chạy từ `1` $\\longrightarrow$ `n`\n",
    "- Các phần tử cột đầu tiên nhận giá trị bằng `1`\n",
    "- Các phần tử cột cuối cùng nhận giá trị bằng `n`\n",
    "- Các phần tử còn lại tính theo mô tả sau\n",
    "    ![Phần tử hàng dưới bằng trung bình ba phần tử xung quanh ở hàng trên](/home/gudchant/data1-numpy/data1-numpy/excercises/image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2. 3. 4.]\n",
      " [1. 2. 3. 4.]\n",
      " [1. 2. 3. 4.]\n",
      " [1. 2. 3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "m = 4\n",
    "n = 4\n",
    "\n",
    "arr = np.ones((m, n))\n",
    "\n",
    "for i in range(n):\n",
    "    arr[0][i] = i+1\n",
    "\n",
    "for j in range(m):\n",
    "    arr[j][n-1] = 1\n",
    "    arr[j][n-1] = n\n",
    "\n",
    "for a in range(1, m):\n",
    "    for b in range(1, n-1):\n",
    "        arr[a][b] = (arr[a-1][b-1] + arr[a-1][b] + arr[a-1][b+1]) / 3\n",
    "\n",
    "print(arr)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bài tập 4\n",
    "Bài tập này sẽ cho các bạn thấy được việc vector hoá quá trình tính toán sẽ tăng tốc độ hiệu quả tới mức nào\n",
    "\n",
    "Trong bài tập này, các bạn cũng sẽ được giới thiệu với một thuật toán Machine Learning (nhưng các bạn hiện tại chưa cần hiểu nó đang làm gì)\n",
    "\n",
    "1. Bài tập này gồm 2 file: Một file Jupyter notebook `knn.ipynb` và một file Python `k_nearest_neighbor.py` chứa phần code các bạn sẽ phải implement\n",
    "2. Trong notebook, biến `num_training` là số phần tử của tập training cho mô hình. Đối với vài tập numpy này, nó là số chiều thứ nhất của ma trận mà các bạn sẽ phải tính toán (property `X_train` của class `KNearestNeighbor`). Chiều còn lại của ma trận này là dữ liệu ảnh đã được \"flatten\" (biến từ ma trận nhiều chiều thành vector), có kích thước ~3000\n",
    "3. Biến `num_training` ban đầu được đặt là 2000, nghĩa là chỉ lấy 2000 ảnh cho việc huấn luyện và chỉ tính toán với 2000 vector đối với numpy. Hãy thử implement numpy đối với các hàm được yêu cầu trong class này đối với số luọng dữ liệu này trước.\n",
    "\n",
    "    Bài tập có yêu cầu các bạn tính toán [khoảng cách L2](https://vi.wikipedia.org/wiki/Kho%E1%BA%A3ng_c%C3%A1ch_Euclid). Các bạn có thể tham khảo thêm về cách tính khoảng cách này [ở đây](https://www.geeksforgeeks.org/calculate-the-euclidean-distance-using-numpy/)\n",
    "\n",
    "4. Tối ưu hoá: Yêu cầu của bài tập này là thuật toán phải hoạt động hiểu quả với số `num_training` _ít nhất_ là __5000__. Các bạn có thể kiểm tra implementation của mình đối với toàn bộ dữ liệu đã có (50000 ảnh)\n",
    "\n",
    "    Các bạn có máy tính RAM to có thể không gặp vấn đề gì với 2000 ảnh, nhưng với 5000 ảnh gần như chắc chắc các implementation kiểu \"hacker\" một dòng sẽ đều gặp phải vấn đề. Mình cũng đã bị dính lỗi như vậy\n",
    "\n",
    "5. Thời gian: Trong cell code cuối của notebook có phần so sánh thời gian thực hiện thuật toán. Với implementation của mình thì thời gian xử lý 5000 ảnh giảm từ ~1 phút (đối với implementation loop) xuống còn ~0.4s. Từ đây các bạn sẽ thấy được sức mạnh của việc tính toán bằng numpy và xử lý vector hoá."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2673, 5053, 7481, ..., 1835, 6695, 4447],\n",
       "       [9305, 2816, 2679, ..., 6094, 4151, 3666],\n",
       "       [8161,  512, 6611, ..., 5342, 2003, 6621],\n",
       "       ...,\n",
       "       [ 573, 4064, 1093, ..., 6270, 1161, 7693],\n",
       "       [5528, 6136, 5183, ..., 5137, 8784, 2570],\n",
       "       [8715, 2194, 4117, ..., 6756, 9607, 3229]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.randint(1,10000, (2000,1000))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([318, 230, 707, 391, 466, 599,  92, 300, 704, 419,  24,   2, 850,\n",
       "       467, 417, 799, 323, 553, 424, 299, 736, 419, 295, 774, 235, 130,\n",
       "       785,  29, 815, 431, 684, 358, 913, 414, 321, 487, 126, 795, 317,\n",
       "        79, 392,  94, 696, 716, 989, 463, 431, 807, 168, 491, 155, 652,\n",
       "        51,  87, 257, 734, 645, 825, 819, 963, 847, 132, 231, 353, 342,\n",
       "       353, 387, 824, 638, 245, 634, 643, 651, 183, 808, 466, 809, 639,\n",
       "       853, 171, 280, 844, 824, 142, 591, 666, 738, 358, 362, 990, 513,\n",
       "       298, 472, 720, 230, 159,  23, 470, 798, 551, 163, 992, 894, 247,\n",
       "       332,   8, 633, 833, 129, 477,  74, 849,  74, 469, 807, 905, 513,\n",
       "       837, 146, 925, 417, 584, 493, 967,  44,  78, 385, 850, 527, 653,\n",
       "       426, 107, 841, 764, 872, 918, 448, 650, 824, 200, 216, 692, 108,\n",
       "       571, 276, 726,  20, 481, 256, 538, 198, 625, 177, 701, 588, 191,\n",
       "       874, 442, 341, 326, 816, 784, 919, 744, 426,  77, 398, 263,  60,\n",
       "       913, 431, 521, 477, 380, 568, 934,  98, 156, 416, 342, 140, 106,\n",
       "       988, 251, 728, 331,  78, 812, 390, 763, 600, 986, 643, 307, 956,\n",
       "       754, 513, 618, 669, 597, 136, 303, 354, 952, 400, 564, 132, 972,\n",
       "       769, 237, 678,   7, 629,  11, 597, 689, 104, 396, 444, 853, 731,\n",
       "        53, 850, 848, 929,  47, 544, 692, 353, 158, 349, 907, 141, 716,\n",
       "        39, 425, 594, 794, 868, 616, 760,  54, 931, 983, 542, 334, 811,\n",
       "       228, 279, 735, 450, 695, 303, 652, 966, 478, 298, 600, 727, 977,\n",
       "       971,  41, 835,  30, 363, 818, 246, 183, 962, 245, 890, 677,  47,\n",
       "        38, 414, 118, 228, 501, 335, 729, 839, 748, 852, 436, 524, 144,\n",
       "       411, 979, 900, 259, 631, 903, 497, 866, 673, 925, 776, 152, 472,\n",
       "       923, 246, 181, 654, 726, 445,  95, 125, 528, 176, 164, 452, 697,\n",
       "       911, 237, 342, 956, 292, 788,  33, 221, 841, 577,  96, 120, 664,\n",
       "       257, 474, 573, 413, 799,  59, 554, 191, 922, 582, 924, 386, 223,\n",
       "       687, 691, 806, 311, 235, 637, 981, 383, 359, 368,  22,  14, 186,\n",
       "       856, 759, 955, 962, 203, 844, 268, 802, 788, 767, 381, 584, 590,\n",
       "       623, 392, 591, 438, 183, 609, 108, 370, 452,  56, 617, 589, 585,\n",
       "       266, 651, 519, 522, 576,  46, 933, 299, 467, 734, 864, 535,  13,\n",
       "       683, 490, 169, 716, 985, 715, 331, 400, 117, 194, 463,  91, 237,\n",
       "       988, 765, 219, 670, 955, 287, 311, 581, 996, 236, 974, 420, 538,\n",
       "       732, 850, 596, 819, 956, 287, 720, 618, 673, 275, 472, 756,  78,\n",
       "         7, 162, 838, 192, 303,   3,   0, 719, 550, 841, 770, 199, 855,\n",
       "       425, 198, 323, 468, 711, 844, 340, 267, 289, 716, 834, 230, 980,\n",
       "         8, 807,  35, 155,  38, 833, 888, 768, 621, 217, 979, 642, 283,\n",
       "        24, 970, 217, 418, 935, 172, 243, 379, 908, 690, 654, 345, 109,\n",
       "       826, 511, 355, 747, 996,  95, 783, 533, 648, 575, 700, 610, 587,\n",
       "       196, 545,  42, 403, 469, 672, 227, 675, 244, 937,  49, 527, 680,\n",
       "       390, 506, 377, 902, 226, 732, 962,  39, 508, 243, 874, 117, 263,\n",
       "       183, 574, 739, 942, 827, 491, 888, 220, 822, 275, 592, 420, 450,\n",
       "       245, 684, 749, 873, 799, 148, 261, 309, 970, 601, 598,  66, 748,\n",
       "       400, 125, 537, 397, 467, 152,  20, 416, 850, 822,  84, 346, 340,\n",
       "       637, 835, 607, 275, 721, 233, 476, 890, 200, 579, 489, 593, 746,\n",
       "       906,  54, 253,  76, 535, 676, 142,  60, 104, 505, 673, 932, 303,\n",
       "        27, 685, 399, 730, 355, 366, 636, 759, 842, 402, 635, 899, 245,\n",
       "       627, 423, 276, 136, 733, 110, 233, 103, 533, 707, 172, 206, 850,\n",
       "       598, 478,  47, 355, 695, 840, 909, 434, 813, 607, 822, 805, 581,\n",
       "       826, 992, 688, 985, 966, 199, 113, 435, 414, 559, 576, 323, 356,\n",
       "       463, 320,  65, 730, 628, 915, 205, 914, 441, 196, 947, 233, 816,\n",
       "       913, 554, 178,  96, 979, 250, 464, 143,  55, 212, 163, 765, 475,\n",
       "       983, 909, 612, 269, 709, 236, 804, 234, 720, 912, 149, 329, 544,\n",
       "        34, 832, 735,  53, 346, 385, 375, 937, 607, 760, 623, 176, 852,\n",
       "       549, 858, 990, 387, 579, 659, 386, 426, 151, 313, 273,  16, 728,\n",
       "       664, 202,  41, 547, 141, 962, 705, 872, 753, 314, 790, 724, 212,\n",
       "        26, 293, 467, 859, 200, 923, 990, 606, 643, 854, 891, 331, 523,\n",
       "       221, 945, 789, 711, 912, 471, 498, 161, 378, 394, 554, 244, 624,\n",
       "       375, 501, 963, 876, 919, 332, 466, 566, 185, 368, 838, 734,  77,\n",
       "       200,  71, 494, 822, 916,  38, 917, 735, 330,  69, 623, 615, 978,\n",
       "       294, 429, 821, 930, 922, 990, 477, 622, 307, 758, 228,  58, 631,\n",
       "       354, 782, 140, 895,  55, 191,  72, 702, 437, 589, 582, 469, 698,\n",
       "       651, 162, 766, 409, 916, 459, 108,  18, 711, 841, 313, 547, 229,\n",
       "       674, 671, 981, 689, 779, 560, 220, 341, 761, 242, 736, 451,  97,\n",
       "       284, 547, 294, 914, 834, 724, 136, 303, 953, 835, 484, 452, 348,\n",
       "       827, 192, 909, 118, 227, 723, 672, 601, 974,  65, 971, 516, 212,\n",
       "       564, 600, 713, 759, 405, 569, 224, 794, 657, 472, 599, 808, 567,\n",
       "       219, 651, 898, 153, 366, 974,  63,  77, 463, 573, 532, 521, 904,\n",
       "       605, 678, 140, 221, 152, 340, 799,  52, 468, 107, 248, 396, 775,\n",
       "       597, 703,  34, 777, 705, 869, 257, 693, 579,  87, 512,  54, 640,\n",
       "       386,   8,   2, 905, 724, 249, 163,  42, 891, 442, 231, 748, 665,\n",
       "       564, 236, 506,  38, 410, 521, 798, 444, 430, 654,  78, 711, 770,\n",
       "       877, 379, 667, 241, 627, 165, 411, 921, 783, 948, 506, 568, 966,\n",
       "       241, 380,  66, 753, 566, 857,  41, 990, 614, 111, 224, 229, 257,\n",
       "       223, 389, 630, 457,  57, 555, 553, 616, 534,  89, 560, 154, 583,\n",
       "       379, 236,  33, 543, 359, 581, 942,  60, 289, 765, 379, 215, 827,\n",
       "       517, 616, 585,  85, 918, 477, 310, 343, 878, 720, 590, 231, 227,\n",
       "       161, 388, 305, 681, 500, 250, 634, 743, 624, 799, 287, 423])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.random.randint(0,999,1000)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318\n",
      "3988\n"
     ]
    }
   ],
   "source": [
    "print(b[0])\n",
    "print(a[0, b[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.988e+03, 4.857e+03, 4.146e+03, 1.902e+03, 3.163e+03, 8.000e+00,\n",
       "       6.456e+03, 6.336e+03, 5.320e+02, 7.467e+03, 8.793e+03, 5.779e+03,\n",
       "       7.417e+03, 9.871e+03, 1.856e+03, 9.951e+03, 4.429e+03, 2.175e+03,\n",
       "       1.610e+02, 7.947e+03, 6.444e+03, 2.229e+03, 9.187e+03, 7.720e+02,\n",
       "       8.468e+03, 3.467e+03, 1.458e+03, 6.140e+02, 6.399e+03, 3.319e+03,\n",
       "       3.550e+03, 3.452e+03, 9.687e+03, 9.555e+03, 8.321e+03, 6.987e+03,\n",
       "       5.170e+03, 9.008e+03, 4.730e+02, 4.957e+03, 7.612e+03, 5.812e+03,\n",
       "       9.595e+03, 8.881e+03, 5.007e+03, 3.140e+02, 3.165e+03, 2.051e+03,\n",
       "       9.240e+03, 9.452e+03, 8.574e+03, 9.482e+03, 4.110e+03, 1.296e+03,\n",
       "       8.419e+03, 4.208e+03, 8.606e+03, 4.808e+03, 2.886e+03, 4.700e+03,\n",
       "       2.902e+03, 5.739e+03, 7.913e+03, 1.913e+03, 2.319e+03, 3.070e+03,\n",
       "       7.759e+03, 7.424e+03, 5.159e+03, 8.211e+03, 3.412e+03, 2.629e+03,\n",
       "       9.706e+03, 1.456e+03, 9.428e+03, 8.851e+03, 5.714e+03, 9.390e+03,\n",
       "       8.606e+03, 7.030e+03, 7.462e+03, 7.947e+03, 7.216e+03, 8.625e+03,\n",
       "       4.123e+03, 9.035e+03, 6.229e+03, 2.059e+03, 1.121e+03, 9.389e+03,\n",
       "       3.006e+03, 3.081e+03, 7.003e+03, 4.693e+03, 3.954e+03, 6.216e+03,\n",
       "       4.213e+03, 3.372e+03, 6.383e+03, 1.861e+03, 4.505e+03, 6.484e+03,\n",
       "       5.371e+03, 7.140e+02, 8.316e+03, 8.491e+03, 1.762e+03, 3.418e+03,\n",
       "       2.012e+03, 4.300e+03, 4.621e+03, 2.530e+03, 7.251e+03, 1.176e+03,\n",
       "       1.872e+03, 2.866e+03, 7.734e+03, 5.122e+03, 9.236e+03, 3.820e+03,\n",
       "       8.415e+03, 3.469e+03, 6.779e+03, 1.829e+03, 9.707e+03, 3.796e+03,\n",
       "       7.322e+03, 1.300e+03, 9.451e+03, 4.920e+02, 2.737e+03, 2.692e+03,\n",
       "       3.586e+03, 8.616e+03, 3.033e+03, 8.301e+03, 6.940e+02, 5.091e+03,\n",
       "       3.764e+03, 1.844e+03, 4.402e+03, 7.733e+03, 2.227e+03, 5.716e+03,\n",
       "       7.813e+03, 9.803e+03, 1.573e+03, 5.357e+03, 5.235e+03, 3.168e+03,\n",
       "       1.485e+03, 8.989e+03, 2.468e+03, 3.538e+03, 3.254e+03, 5.503e+03,\n",
       "       9.135e+03, 4.563e+03, 7.480e+02, 9.300e+02, 5.240e+02, 3.390e+03,\n",
       "       1.714e+03, 9.631e+03, 8.279e+03, 7.210e+02, 8.544e+03, 7.859e+03,\n",
       "       9.091e+03, 8.931e+03, 5.180e+02, 5.742e+03, 3.060e+03, 7.880e+03,\n",
       "       6.130e+03, 4.387e+03, 6.701e+03, 7.472e+03, 6.608e+03, 1.676e+03,\n",
       "       7.180e+02, 4.945e+03, 3.767e+03, 2.977e+03, 2.563e+03, 1.262e+03,\n",
       "       8.388e+03, 2.189e+03, 3.681e+03, 9.729e+03, 1.971e+03, 3.916e+03,\n",
       "       1.565e+03, 6.333e+03, 8.717e+03, 4.302e+03, 9.479e+03, 1.320e+03,\n",
       "       4.865e+03, 8.577e+03, 2.878e+03, 3.910e+02, 5.795e+03, 8.040e+02,\n",
       "       1.786e+03, 6.860e+03, 1.780e+03, 4.309e+03, 5.265e+03, 7.758e+03,\n",
       "       3.329e+03, 7.840e+02, 4.922e+03, 6.490e+03, 3.090e+02, 4.170e+02,\n",
       "       4.175e+03, 7.659e+03, 8.091e+03, 9.290e+03, 1.803e+03, 8.438e+03,\n",
       "       7.953e+03, 7.817e+03, 2.223e+03, 5.488e+03, 8.960e+02, 4.710e+02,\n",
       "       8.787e+03, 6.653e+03, 8.615e+03, 4.836e+03, 8.633e+03, 6.042e+03,\n",
       "       7.330e+03, 6.016e+03, 4.660e+03, 8.415e+03, 8.214e+03, 3.784e+03,\n",
       "       8.511e+03, 5.859e+03, 4.751e+03, 9.837e+03, 5.520e+02, 7.077e+03,\n",
       "       1.397e+03, 2.887e+03, 7.539e+03, 7.090e+02, 1.455e+03, 6.623e+03,\n",
       "       4.603e+03, 1.302e+03, 2.747e+03, 7.894e+03, 2.420e+03, 6.403e+03,\n",
       "       9.938e+03, 3.580e+02, 3.980e+03, 1.175e+03, 5.362e+03, 7.774e+03,\n",
       "       4.401e+03, 1.321e+03, 3.811e+03, 3.630e+02, 9.156e+03, 4.450e+02,\n",
       "       4.135e+03, 9.755e+03, 6.344e+03, 7.104e+03, 6.048e+03, 8.409e+03,\n",
       "       8.073e+03, 1.980e+03, 5.102e+03, 4.782e+03, 3.540e+03, 4.420e+02,\n",
       "       7.820e+03, 4.641e+03, 5.809e+03, 7.362e+03, 4.875e+03, 4.134e+03,\n",
       "       6.597e+03, 7.179e+03, 7.722e+03, 8.685e+03, 5.841e+03, 4.410e+02,\n",
       "       2.395e+03, 9.106e+03, 3.754e+03, 1.207e+03, 1.554e+03, 2.909e+03,\n",
       "       6.610e+03, 4.415e+03, 3.935e+03, 7.762e+03, 6.298e+03, 4.784e+03,\n",
       "       7.190e+03, 7.086e+03, 3.415e+03, 5.958e+03, 3.010e+02, 5.886e+03,\n",
       "       5.328e+03, 9.554e+03, 7.147e+03, 9.847e+03, 2.016e+03, 4.009e+03,\n",
       "       2.061e+03, 5.292e+03, 1.160e+02, 5.865e+03, 9.767e+03, 6.727e+03,\n",
       "       6.619e+03, 5.604e+03, 5.518e+03, 7.718e+03, 1.781e+03, 4.361e+03,\n",
       "       3.256e+03, 1.314e+03, 3.562e+03, 3.657e+03, 6.005e+03, 3.498e+03,\n",
       "       1.635e+03, 5.158e+03, 1.357e+03, 5.120e+02, 3.353e+03, 3.399e+03,\n",
       "       5.729e+03, 5.858e+03, 7.946e+03, 2.627e+03, 6.065e+03, 7.331e+03,\n",
       "       4.476e+03, 8.843e+03, 8.088e+03, 2.303e+03, 7.109e+03, 2.304e+03,\n",
       "       5.818e+03, 8.845e+03, 2.413e+03, 7.337e+03, 3.590e+03, 6.430e+03,\n",
       "       4.434e+03, 9.360e+03, 4.153e+03, 8.854e+03, 2.429e+03, 2.100e+03,\n",
       "       9.133e+03, 3.621e+03, 2.692e+03, 1.059e+03, 5.600e+02, 4.250e+03,\n",
       "       8.303e+03, 1.801e+03, 3.841e+03, 2.863e+03, 4.346e+03, 2.206e+03,\n",
       "       2.390e+02, 8.341e+03, 4.185e+03, 9.477e+03, 6.725e+03, 3.919e+03,\n",
       "       6.260e+02, 5.028e+03, 2.809e+03, 9.817e+03, 1.784e+03, 1.335e+03,\n",
       "       9.182e+03, 2.386e+03, 2.771e+03, 7.696e+03, 2.063e+03, 6.270e+02,\n",
       "       8.516e+03, 8.095e+03, 8.765e+03, 7.406e+03, 3.807e+03, 6.345e+03,\n",
       "       3.870e+03, 3.521e+03, 2.287e+03, 3.786e+03, 2.630e+02, 3.200e+03,\n",
       "       3.940e+03, 3.253e+03, 5.245e+03, 2.721e+03, 9.288e+03, 4.048e+03,\n",
       "       3.394e+03, 4.088e+03, 8.671e+03, 8.370e+02, 6.388e+03, 7.149e+03,\n",
       "       1.204e+03, 4.830e+03, 1.593e+03, 5.300e+01, 8.836e+03, 6.278e+03,\n",
       "       1.483e+03, 4.349e+03, 9.736e+03, 6.512e+03, 9.143e+03, 1.312e+03,\n",
       "       1.966e+03, 2.379e+03, 4.198e+03, 9.269e+03, 3.967e+03, 7.920e+03,\n",
       "       5.161e+03, 1.377e+03, 3.764e+03, 2.367e+03, 7.491e+03, 1.923e+03,\n",
       "       9.758e+03, 7.153e+03, 3.541e+03, 7.983e+03, 9.579e+03, 5.130e+03,\n",
       "       5.105e+03, 9.484e+03, 8.772e+03, 5.865e+03, 2.627e+03, 7.000e+03,\n",
       "       8.403e+03, 2.867e+03, 3.639e+03, 9.400e+03, 5.100e+02, 3.370e+03,\n",
       "       2.608e+03, 9.450e+03, 3.794e+03, 5.195e+03, 8.104e+03, 3.900e+02,\n",
       "       2.809e+03, 1.437e+03, 1.430e+03, 7.450e+03, 9.258e+03, 8.673e+03,\n",
       "       8.912e+03, 4.335e+03, 9.997e+03, 5.793e+03, 3.567e+03, 8.676e+03,\n",
       "       6.644e+03, 9.140e+03, 6.515e+03, 4.910e+03, 4.427e+03, 8.324e+03,\n",
       "       3.020e+03, 2.997e+03, 1.655e+03, 6.022e+03, 2.588e+03, 3.640e+02,\n",
       "       8.851e+03, 8.000e+00, 8.153e+03, 2.390e+03, 4.030e+02, 3.531e+03,\n",
       "       9.882e+03, 5.127e+03, 4.946e+03, 9.082e+03, 1.911e+03, 5.640e+02,\n",
       "       9.020e+03, 1.487e+03, 6.692e+03, 3.346e+03, 1.242e+03, 6.572e+03,\n",
       "       2.939e+03, 7.660e+03, 8.546e+03, 4.526e+03, 6.057e+03, 1.720e+02,\n",
       "       9.314e+03, 1.768e+03, 9.542e+03, 9.410e+03, 3.267e+03, 3.810e+02,\n",
       "       2.408e+03, 7.458e+03, 1.571e+03, 6.560e+02, 8.646e+03, 3.624e+03,\n",
       "       2.959e+03, 6.576e+03, 5.268e+03, 5.040e+02, 4.031e+03, 8.156e+03,\n",
       "       9.332e+03, 8.262e+03, 2.330e+03, 9.223e+03, 8.667e+03, 8.900e+03,\n",
       "       7.810e+02, 7.787e+03, 8.436e+03, 2.473e+03, 8.622e+03, 8.851e+03,\n",
       "       7.078e+03, 5.870e+02, 1.723e+03, 4.612e+03, 3.472e+03, 9.205e+03,\n",
       "       8.460e+02, 4.395e+03, 3.058e+03, 7.831e+03, 2.342e+03, 7.587e+03,\n",
       "       6.460e+03, 7.476e+03, 8.002e+03, 7.038e+03, 1.125e+03, 1.123e+03,\n",
       "       1.248e+03, 3.600e+02, 3.634e+03, 7.458e+03, 4.534e+03, 6.151e+03,\n",
       "       6.907e+03, 5.237e+03, 3.120e+03, 9.394e+03, 5.561e+03, 6.294e+03,\n",
       "       5.690e+02, 5.068e+03, 7.798e+03, 8.755e+03, 2.177e+03, 4.354e+03,\n",
       "       8.607e+03, 1.513e+03, 3.389e+03, 9.579e+03, 2.257e+03, 5.598e+03,\n",
       "       3.674e+03, 2.590e+02, 7.250e+02, 2.430e+03, 4.938e+03, 8.034e+03,\n",
       "       1.248e+03, 1.346e+03, 5.988e+03, 9.203e+03, 4.962e+03, 5.427e+03,\n",
       "       7.558e+03, 5.216e+03, 4.599e+03, 4.478e+03, 4.718e+03, 4.820e+02,\n",
       "       1.804e+03, 2.284e+03, 8.507e+03, 8.855e+03, 6.870e+03, 2.248e+03,\n",
       "       7.475e+03, 1.050e+02, 1.623e+03, 3.803e+03, 9.900e+02, 6.968e+03,\n",
       "       4.337e+03, 7.696e+03, 5.065e+03, 7.044e+03, 1.135e+03, 2.428e+03,\n",
       "       5.048e+03, 6.004e+03, 7.119e+03, 1.580e+03, 6.910e+02, 5.526e+03,\n",
       "       6.430e+02, 7.106e+03, 7.227e+03, 7.375e+03, 9.464e+03, 2.349e+03,\n",
       "       2.069e+03, 8.677e+03, 5.578e+03, 6.575e+03, 2.276e+03, 6.665e+03,\n",
       "       4.135e+03, 1.284e+03, 8.275e+03, 5.290e+02, 8.810e+03, 9.522e+03,\n",
       "       7.001e+03, 9.603e+03, 1.889e+03, 9.050e+02, 4.822e+03, 7.320e+03,\n",
       "       9.209e+03, 6.158e+03, 8.455e+03, 8.822e+03, 2.300e+03, 7.956e+03,\n",
       "       3.633e+03, 2.378e+03, 1.451e+03, 7.343e+03, 4.591e+03, 3.826e+03,\n",
       "       9.180e+03, 7.954e+03, 3.389e+03, 7.722e+03, 8.999e+03, 6.812e+03,\n",
       "       4.639e+03, 8.139e+03, 2.242e+03, 4.807e+03, 2.798e+03, 6.080e+03,\n",
       "       8.679e+03, 3.289e+03, 7.902e+03, 2.850e+03, 4.918e+03, 8.085e+03,\n",
       "       8.452e+03, 1.490e+03, 3.090e+02, 2.993e+03, 7.260e+02, 6.140e+02,\n",
       "       7.373e+03, 6.937e+03, 2.886e+03, 9.904e+03, 3.455e+03, 1.625e+03,\n",
       "       1.867e+03, 6.615e+03, 2.467e+03, 2.540e+03, 8.251e+03, 7.854e+03,\n",
       "       3.629e+03, 4.592e+03, 4.380e+02, 1.313e+03, 2.395e+03, 9.069e+03,\n",
       "       3.930e+02, 9.585e+03, 6.799e+03, 8.915e+03, 6.139e+03, 8.563e+03,\n",
       "       3.018e+03, 7.377e+03, 6.849e+03, 1.448e+03, 8.736e+03, 9.680e+02,\n",
       "       7.702e+03, 9.672e+03, 6.648e+03, 9.172e+03, 8.272e+03, 2.965e+03,\n",
       "       6.337e+03, 4.680e+03, 4.684e+03, 8.446e+03, 8.944e+03, 4.910e+03,\n",
       "       5.798e+03, 2.892e+03, 4.162e+03, 5.488e+03, 8.090e+02, 5.320e+03,\n",
       "       3.657e+03, 2.964e+03, 2.071e+03, 9.882e+03, 6.327e+03, 4.133e+03,\n",
       "       6.199e+03, 5.651e+03, 3.924e+03, 5.311e+03, 6.524e+03, 3.231e+03,\n",
       "       9.761e+03, 5.554e+03, 3.930e+03, 9.107e+03, 7.069e+03, 4.854e+03,\n",
       "       3.522e+03, 6.680e+03, 6.983e+03, 9.940e+03, 5.086e+03, 5.026e+03,\n",
       "       5.262e+03, 9.132e+03, 7.593e+03, 9.577e+03, 2.078e+03, 1.766e+03,\n",
       "       4.505e+03, 2.993e+03, 9.399e+03, 6.610e+02, 4.224e+03, 8.476e+03,\n",
       "       9.253e+03, 9.929e+03, 6.663e+03, 7.425e+03, 8.464e+03, 5.794e+03,\n",
       "       3.174e+03, 4.329e+03, 9.774e+03, 8.133e+03, 3.707e+03, 9.898e+03,\n",
       "       6.440e+03, 3.786e+03, 2.754e+03, 7.435e+03, 9.447e+03, 6.654e+03,\n",
       "       7.475e+03, 6.246e+03, 6.709e+03, 9.337e+03, 3.329e+03, 2.695e+03,\n",
       "       6.516e+03, 5.747e+03, 9.444e+03, 1.458e+03, 1.089e+03, 1.632e+03,\n",
       "       1.037e+03, 7.293e+03, 9.089e+03, 5.785e+03, 5.570e+02, 7.130e+02,\n",
       "       7.022e+03, 2.516e+03, 6.310e+03, 1.374e+03, 3.620e+03, 1.382e+03,\n",
       "       6.166e+03, 1.808e+03, 6.506e+03, 6.346e+03, 6.595e+03, 1.103e+03,\n",
       "       1.762e+03, 1.083e+03, 5.184e+03, 1.044e+03, 1.651e+03, 1.878e+03,\n",
       "       8.550e+02, 1.573e+03, 3.525e+03, 9.576e+03, 8.341e+03, 4.909e+03,\n",
       "       8.052e+03, 4.150e+03, 2.557e+03, 2.220e+02, 3.053e+03, 1.784e+03,\n",
       "       3.890e+02, 3.920e+02, 8.389e+03, 4.346e+03, 9.154e+03, 3.888e+03,\n",
       "       2.580e+03, 7.607e+03, 1.017e+03, 4.476e+03, 2.230e+03, 5.132e+03,\n",
       "       9.972e+03, 3.195e+03, 2.694e+03, 5.469e+03, 8.150e+03, 2.947e+03,\n",
       "       5.350e+02, 6.652e+03, 5.950e+03, 7.624e+03, 9.693e+03, 4.220e+03,\n",
       "       5.216e+03, 1.836e+03, 5.813e+03, 9.999e+03, 3.385e+03, 6.610e+02,\n",
       "       4.771e+03, 1.617e+03, 3.276e+03, 7.065e+03, 4.428e+03, 3.232e+03,\n",
       "       9.500e+01, 2.280e+03, 1.282e+03, 7.966e+03, 1.507e+03, 9.117e+03,\n",
       "       5.183e+03, 2.795e+03, 5.319e+03, 3.289e+03, 6.290e+02, 2.488e+03,\n",
       "       7.164e+03, 1.332e+03, 2.901e+03, 5.325e+03, 8.172e+03, 7.548e+03,\n",
       "       1.192e+03, 7.869e+03, 1.436e+03, 9.195e+03, 9.673e+03, 6.523e+03,\n",
       "       2.508e+03, 6.839e+03, 1.942e+03, 6.995e+03, 6.862e+03, 1.113e+03,\n",
       "       3.296e+03, 7.199e+03, 6.195e+03, 2.042e+03, 7.461e+03, 9.390e+02,\n",
       "       5.560e+03, 5.813e+03, 6.510e+03, 6.558e+03, 5.699e+03, 7.190e+03,\n",
       "       2.380e+03, 6.350e+03, 5.793e+03, 8.800e+01, 7.896e+03, 2.850e+03,\n",
       "       7.720e+03, 3.700e+01, 1.447e+03, 7.903e+03, 1.436e+03, 3.766e+03,\n",
       "       6.236e+03, 3.450e+02, 3.762e+03, 1.120e+02, 8.635e+03, 3.089e+03,\n",
       "       4.614e+03, 9.577e+03, 8.980e+03, 4.122e+03, 5.752e+03, 3.368e+03,\n",
       "       6.567e+03, 9.335e+03, 5.684e+03, 6.470e+02, 2.931e+03, 1.055e+03,\n",
       "       5.922e+03, 6.758e+03, 4.035e+03, 5.017e+03, 1.930e+02, 1.498e+03,\n",
       "       1.581e+03, 7.884e+03, 7.686e+03, 3.987e+03, 1.396e+03, 5.512e+03,\n",
       "       7.803e+03, 2.611e+03, 3.855e+03, 1.352e+03, 9.689e+03, 6.305e+03,\n",
       "       9.632e+03, 7.380e+02, 5.246e+03, 6.121e+03, 8.888e+03, 6.073e+03,\n",
       "       8.382e+03, 9.207e+03, 2.862e+03, 1.868e+03, 1.546e+03, 1.703e+03,\n",
       "       1.968e+03, 6.037e+03, 7.735e+03, 5.168e+03, 7.430e+02, 7.300e+03,\n",
       "       5.736e+03, 2.240e+02, 7.830e+02, 7.363e+03, 3.652e+03, 8.390e+03,\n",
       "       5.989e+03, 3.546e+03, 8.499e+03, 7.000e+02, 7.750e+03, 9.770e+02,\n",
       "       4.058e+03, 6.498e+03, 7.378e+03, 8.130e+03])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.zeros(b.shape)\n",
    "\n",
    "for i in range(arr.shape[0]):\n",
    "    arr[i] = a[i, b[i]]\n",
    "\n",
    "arr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
